{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2548968,"sourceType":"datasetVersion","datasetId":1546009}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Stroke Risk Prediction Model Development with Data Imbalance Handling**","metadata":{}},{"cell_type":"markdown","source":"# **Introduction**\nThe aim of this project is to develop a machine learning model for predicting the risk of stroke. The dataset used consists of multiple health-related attributes, such as age, hypertension, heart disease, and other medical features. The model's goal is to predict whether a person has a high risk of stroke, based on these features.\n\nWe will be using various techniques in data mining, including data preprocessing, model training, evaluation, and performance metrics. For this purpose, we'll be employing classification algorithms such as Random Forest and evaluating the model using accuracy, ROC curve, and AUC score.","metadata":{}},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/cerebral-stroke-predictionimbalaced-dataset/dataset.csv\")\ndata.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:27:59.678969Z","iopub.execute_input":"2025-03-15T16:27:59.679320Z","iopub.status.idle":"2025-03-15T16:27:59.789809Z","shell.execute_reply.started":"2025-03-15T16:27:59.679295Z","shell.execute_reply":"2025-03-15T16:27:59.788682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:44.567981Z","iopub.execute_input":"2025-03-15T16:21:44.568362Z","iopub.status.idle":"2025-03-15T16:21:44.590536Z","shell.execute_reply.started":"2025-03-15T16:21:44.568330Z","shell.execute_reply":"2025-03-15T16:21:44.589506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:46.179616Z","iopub.execute_input":"2025-03-15T16:21:46.179960Z","iopub.status.idle":"2025-03-15T16:21:46.214187Z","shell.execute_reply.started":"2025-03-15T16:21:46.179934Z","shell.execute_reply":"2025-03-15T16:21:46.213209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:47.715474Z","iopub.execute_input":"2025-03-15T16:21:47.715876Z","iopub.status.idle":"2025-03-15T16:21:47.735383Z","shell.execute_reply.started":"2025-03-15T16:21:47.715841Z","shell.execute_reply":"2025-03-15T16:21:47.734349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:49.226942Z","iopub.execute_input":"2025-03-15T16:21:49.227306Z","iopub.status.idle":"2025-03-15T16:21:49.233255Z","shell.execute_reply.started":"2025-03-15T16:21:49.227276Z","shell.execute_reply":"2025-03-15T16:21:49.232068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:50.351172Z","iopub.execute_input":"2025-03-15T16:21:50.351547Z","iopub.status.idle":"2025-03-15T16:21:50.358503Z","shell.execute_reply.started":"2025-03-15T16:21:50.351514Z","shell.execute_reply":"2025-03-15T16:21:50.357394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['stroke'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:51.867107Z","iopub.execute_input":"2025-03-15T16:21:51.867438Z","iopub.status.idle":"2025-03-15T16:21:51.874922Z","shell.execute_reply.started":"2025-03-15T16:21:51.867412Z","shell.execute_reply":"2025-03-15T16:21:51.873535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.countplot(x='stroke', data=data)\nplt.title(\"Imbalance data\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:53.201303Z","iopub.execute_input":"2025-03-15T16:21:53.201686Z","iopub.status.idle":"2025-03-15T16:21:53.373589Z","shell.execute_reply.started":"2025-03-15T16:21:53.201652Z","shell.execute_reply":"2025-03-15T16:21:53.372646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **One Hot Encoding**","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:21:55.912138Z","iopub.execute_input":"2025-03-15T16:21:55.912475Z","iopub.status.idle":"2025-03-15T16:21:55.918686Z","shell.execute_reply.started":"2025-03-15T16:21:55.912448Z","shell.execute_reply":"2025-03-15T16:21:55.917373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\n\ndata['gender'] = encoder.fit_transform(data['gender'])\ndata['ever_married'] = encoder.fit_transform(data['ever_married'])\ndata['work_type'] = encoder.fit_transform(data['work_type'])\ndata['Residence_type'] = encoder.fit_transform(data['Residence_type'])\ndata['smoking_status'] = encoder.fit_transform(data['smoking_status'])\n\n# Check the data after Label Encoding\nprint(data.head())\nprint(data.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:28:04.630606Z","iopub.execute_input":"2025-03-15T16:28:04.630965Z","iopub.status.idle":"2025-03-15T16:28:04.696230Z","shell.execute_reply.started":"2025-03-15T16:28:04.630934Z","shell.execute_reply":"2025-03-15T16:28:04.695210Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Label Encoding has successfully transformed categorical columns into numeric values. The dataset contains 43,400 rows. The bmi column has missing values, while others have no missing data. Data types are correctly set as int64 and float64.","metadata":{}},{"cell_type":"markdown","source":"## **Handling Missing Values**","metadata":{}},{"cell_type":"code","source":"# Count the missing values\nprint(\"Missing values:\\n\", data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:22:10.729627Z","iopub.execute_input":"2025-03-15T16:22:10.730101Z","iopub.status.idle":"2025-03-15T16:22:10.738347Z","shell.execute_reply.started":"2025-03-15T16:22:10.730059Z","shell.execute_reply":"2025-03-15T16:22:10.737282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nimport numpy as np\n\nimputer = KNNImputer(missing_values=np.nan)\ntab = imputer.fit_transform(data)\ndata = pd.DataFrame(tab, columns=data.columns)\nprint(data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:28:08.909478Z","iopub.execute_input":"2025-03-15T16:28:08.909950Z","iopub.status.idle":"2025-03-15T16:28:12.877551Z","shell.execute_reply.started":"2025-03-15T16:28:08.909918Z","shell.execute_reply":"2025-03-15T16:28:12.876455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:22:18.246190Z","iopub.execute_input":"2025-03-15T16:22:18.246660Z","iopub.status.idle":"2025-03-15T16:22:18.269922Z","shell.execute_reply.started":"2025-03-15T16:22:18.246593Z","shell.execute_reply":"2025-03-15T16:22:18.268482Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Evaluation Without Resampling**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, roc_curve\nimport matplotlib.pyplot as plt\n\nX = data.drop('stroke', axis=1)\ny = data['stroke']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\nroc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\nprint(f\"ROC-AUC Score: {roc_auc:.4f}\")\n\n# F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\n\nfpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], color='red', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:01:01.539828Z","iopub.execute_input":"2025-03-15T17:01:01.540248Z","iopub.status.idle":"2025-03-15T17:01:05.532047Z","shell.execute_reply.started":"2025-03-15T17:01:01.540216Z","shell.execute_reply":"2025-03-15T17:01:05.530906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **OverSampling (SMOTE)**","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n\nX = data.drop('stroke', axis=1)\ny = data['stroke']\n\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# ROC-AUC\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(\"ROC-AUC:\", roc_auc)\n\n# F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score:\", f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:40:35.384204Z","iopub.execute_input":"2025-03-15T16:40:35.384634Z","iopub.status.idle":"2025-03-15T16:40:45.055185Z","shell.execute_reply.started":"2025-03-15T16:40:35.384585Z","shell.execute_reply":"2025-03-15T16:40:45.053985Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **UnderSampling**","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\nunder_sampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\nX_resampled, y_resampled = under_sampler.fit_resample(X, y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# ROC-AUC\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(\"ROC-AUC:\", roc_auc)\n\n# F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score:\", f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:40:48.172935Z","iopub.execute_input":"2025-03-15T16:40:48.173314Z","iopub.status.idle":"2025-03-15T16:40:48.501854Z","shell.execute_reply.started":"2025-03-15T16:40:48.173285Z","shell.execute_reply":"2025-03-15T16:40:48.500922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Combining OverSampling and UnderSampling**","metadata":{}},{"cell_type":"code","source":"smote = SMOTE(sampling_strategy='auto', random_state=42)\nX_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n\nunder_sampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\nX_resampled_combined, y_resampled_combined = under_sampler.fit_resample(X_resampled_smote, y_resampled_smote)\n\nX_train, X_test, y_train, y_test = train_test_split(X_resampled_combined, y_resampled_combined, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# ROC-AUC\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(\"ROC-AUC:\", roc_auc)\n\n# F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score:\", f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:40:58.003451Z","iopub.execute_input":"2025-03-15T16:40:58.003830Z","iopub.status.idle":"2025-03-15T16:41:07.730726Z","shell.execute_reply.started":"2025-03-15T16:40:58.003803Z","shell.execute_reply":"2025-03-15T16:41:07.729442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **GridSearchCV**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30]}\n\nrf_model = RandomForestClassifier(random_state=42)\n\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best Parameters:\", grid_search.best_params_)\nbest_model = grid_search.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:39:01.528473Z","iopub.execute_input":"2025-03-15T16:39:01.528930Z","iopub.status.idle":"2025-03-15T16:40:34.364119Z","shell.execute_reply.started":"2025-03-15T16:39:01.528897Z","shell.execute_reply":"2025-03-15T16:40:34.362381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = best_model.predict(X_test)\ny_pred_proba = best_model.predict_proba(X_test)[:, 1]\n\n# Accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\n# F1 Score\nf1 = f1_score(y_test, y_pred)\nprint(f\"F1 Score: {f1}\")\n\n# ROC-AUC Score\nauc = roc_auc_score(y_test, y_pred_proba)\nprint(f\"ROC-AUC Score: {auc}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# Classification Report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f\"ROC Curve (AUC = {auc:.2f})\")\nplt.plot([0, 1], [0, 1], color='red', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:56.295213Z","iopub.execute_input":"2025-03-15T16:43:56.295544Z","iopub.status.idle":"2025-03-15T16:43:58.064746Z","shell.execute_reply.started":"2025-03-15T16:43:56.295519Z","shell.execute_reply":"2025-03-15T16:43:58.063631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Conclusion**\nThe stroke risk prediction model achieved 99.12% accuracy, 0.9911 F1-score, and 0.9985 AUC-ROC, indicating excellent performance in distinguishing stroke cases. The low false positives (5 cases) show strong precision, but 219 false negatives suggest a need to improve recall to minimize missed stroke cases.\n\nThe ROC curve confirms near-perfect classification, and the classification report highlights a strong balance between precision and recall.\n\nFuture Recommendations\n* Reduce false negatives by adjusting the classification threshold.\n* Validate on real-world data to ensure generalizability.\n* Explore other models like XGBoost or Neural Networks for potential improvements.\n* Enhance feature selection with additional medical or lifestyle factors.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}